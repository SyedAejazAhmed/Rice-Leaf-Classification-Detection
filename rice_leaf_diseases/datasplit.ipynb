{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b25ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source directory: d:\\Projects\\Rice Leaf Classification & Detection\\rice_leaf_diseases\n",
      "Train directory: d:\\Projects\\Rice Leaf Classification & Detection\\dataset\\train\n",
      "Validation directory: d:\\Projects\\Rice Leaf Classification & Detection\\dataset\\val\n",
      "Test directory: d:\\Projects\\Rice Leaf Classification & Detection\\dataset\\test\n",
      "\n",
      "ðŸ“‚ Processing class: Bacterial leaf blight\n",
      "Total: 40 | Train: 32 | Val: 4 | Test: 4\n",
      "\n",
      "ðŸ“‚ Processing class: Brown spot\n",
      "Total: 40 | Train: 32 | Val: 4 | Test: 4\n",
      "Skipping non-directory: datasplit.ipynb\n",
      "\n",
      "ðŸ“‚ Processing class: Leaf smut\n",
      "Total: 40 | Train: 32 | Val: 4 | Test: 4\n",
      "Dataset split completed successfully!\n",
      "SUMMARY:\n",
      "Total images processed: 120\n",
      "Training set: 96 (80.0%)\n",
      "Validation set: 12 (10.0%)\n",
      "Test set: 12 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def create_dir_if_not_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def split_data(source_dir, train_dir, val_dir, test_dir, train_size=0.8, val_size=0.1, test_size=0.1, random_seed=42):\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    # Validate split sizes\n",
    "    assert abs(train_size + val_size + test_size - 1.0) < 1e-6, \"Split ratios must add up to 1.0\"\n",
    "    \n",
    "    # Convert to absolute paths\n",
    "    source_dir = os.path.abspath(source_dir)\n",
    "    train_dir = os.path.abspath(train_dir)\n",
    "    val_dir = os.path.abspath(val_dir)\n",
    "    test_dir = os.path.abspath(test_dir)\n",
    "    \n",
    "    print(f\"Source directory: {source_dir}\")\n",
    "    print(f\"Train directory: {train_dir}\")\n",
    "    print(f\"Validation directory: {val_dir}\")\n",
    "    print(f\"Test directory: {test_dir}\")\n",
    "    \n",
    "    # Create main output directories\n",
    "    for path in [train_dir, val_dir, test_dir]:\n",
    "        create_dir_if_not_exists(path)\n",
    "\n",
    "    # Image file extensions to include\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}\n",
    "    \n",
    "    total_images = 0\n",
    "    total_train = 0\n",
    "    total_val = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    # For each class folder in the source directory\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_name)\n",
    "\n",
    "        if not os.path.isdir(class_path):\n",
    "            print(f\"Skipping non-directory: {class_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nðŸ“‚ Processing class: {class_name}\")\n",
    "        \n",
    "        # Create class subfolders in each split directory\n",
    "        class_train_path = os.path.join(train_dir, class_name)\n",
    "        class_val_path = os.path.join(val_dir, class_name)\n",
    "        class_test_path = os.path.join(test_dir, class_name)\n",
    "\n",
    "        create_dir_if_not_exists(class_train_path)\n",
    "        create_dir_if_not_exists(class_val_path)\n",
    "        create_dir_if_not_exists(class_test_path)\n",
    "\n",
    "        # Get all image files in class folder (filter by extension)\n",
    "        all_files = os.listdir(class_path)\n",
    "        images = [f for f in all_files \n",
    "                 if os.path.isfile(os.path.join(class_path, f)) and \n",
    "                 os.path.splitext(f)[1].lower() in valid_extensions]\n",
    "        \n",
    "        if not images:\n",
    "            print(f\"âš ï¸  No valid image files found in {class_name}\")\n",
    "            continue\n",
    "            \n",
    "        # Shuffle images for random distribution\n",
    "        random.shuffle(images)\n",
    "\n",
    "        total = len(images)\n",
    "        train_count = int(total * train_size)\n",
    "        val_count = int(total * val_size)\n",
    "        test_count = total - train_count - val_count\n",
    "\n",
    "        # Handle edge case where counts don't add up exactly\n",
    "        if train_count + val_count + test_count != total:\n",
    "            remaining = total - train_count - val_count - test_count\n",
    "            test_count += remaining\n",
    "\n",
    "        train_imgs = images[:train_count]\n",
    "        val_imgs = images[train_count:train_count + val_count]\n",
    "        test_imgs = images[train_count + val_count:]\n",
    "\n",
    "        print(f\"Total: {total} | Train: {len(train_imgs)} | Val: {len(val_imgs)} | Test: {len(test_imgs)}\")\n",
    "        \n",
    "        # Update totals\n",
    "        total_images += total\n",
    "        total_train += len(train_imgs)\n",
    "        total_val += len(val_imgs)\n",
    "        total_test += len(test_imgs)\n",
    "\n",
    "        # Copy files to appropriate directories\n",
    "        for img_list, target_dir, split_name in [\n",
    "            (train_imgs, class_train_path, \"train\"), \n",
    "            (val_imgs, class_val_path, \"val\"), \n",
    "            (test_imgs, class_test_path, \"test\")\n",
    "        ]:\n",
    "            for img in img_list:\n",
    "                src_path = os.path.join(class_path, img)\n",
    "                dst_path = os.path.join(target_dir, img)\n",
    "                try:\n",
    "                    shutil.copy2(src_path, dst_path)  # copy2 preserves metadata\n",
    "                except Exception as e:\n",
    "                    print(f\"Error copying {img} to {split_name}: {e}\")\n",
    "\n",
    "    print(f\"Dataset split completed successfully!\")\n",
    "    print(f\"SUMMARY:\")\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Training set: {total_train} ({total_train/total_images*100:.1f}%)\")\n",
    "    print(f\"Validation set: {total_val} ({total_val/total_images*100:.1f}%)\")\n",
    "    print(f\"Test set: {total_test} ({total_test/total_images*100:.1f}%)\")\n",
    "\n",
    "current_dir = os.getcwd()  # Gets current working directory\n",
    "source_dir = current_dir  # The rice_leaf_diseases folder itself\n",
    "base_output_dir = os.path.join(os.path.dirname(current_dir), 'dataset')\n",
    "train_dir = os.path.join(base_output_dir, 'train')\n",
    "val_dir = os.path.join(base_output_dir, 'val')\n",
    "test_dir = os.path.join(base_output_dir, 'test')\n",
    "split_data(\n",
    "    source_dir=source_dir,\n",
    "    train_dir=train_dir,\n",
    "    val_dir=val_dir,\n",
    "    test_dir=test_dir,\n",
    "    train_size=0.8,    # 80% for training\n",
    "    val_size=0.1,      # 10% for validation  \n",
    "    test_size=0.1,     # 10% for testing\n",
    "    random_seed=42     # For reproducible results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a2013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
